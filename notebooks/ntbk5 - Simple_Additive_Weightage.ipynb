{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1156464",
   "metadata": {},
   "source": [
    "# Simple Additive Weighting (SAW) Method in Multi-Criteria Decision Making\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "Simple Additive Weighting (SAW) is one of the most widely used Multi-Criteria Decision Making (MCDM) methods. It's also known as the **Weighted Sum Model (WSM)** or **Linear Additive Model**. \n",
    "\n",
    "\n",
    "SAW is particularly useful when you need to:\n",
    "\n",
    "- Evaluate alternatives based on multiple criteria\n",
    "\n",
    "- Handle both quantitative and qualitative data\n",
    "\n",
    "- Make decisions with clear, interpretable results\n",
    "\n",
    "\n",
    "\n",
    "### How SAW Works\n",
    "\n",
    "\n",
    "\n",
    "1. **Normalization**: Convert all criteria to a common scale (0-1)\n",
    "\n",
    "2. **Weighting**: Apply importance weights to each criterion\n",
    "\n",
    "3. **Aggregation**: Sum the weighted normalized values for each alternative\n",
    "\n",
    "4. **Ranking**: Select the alternative with the highest total score\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Steps to Perform SAW\n",
    "\n",
    "![AHP Steps](../figures/mermaid/SAW_Steps.png)\n",
    "\n",
    "1. **Construct the Decision Matrix**: List all alternatives and criteria in a table, with values for each criterion per alternative.\n",
    "   \n",
    "A decision matrix in Multi-Criteria Decision Making (MCDM) is a table where rows represent alternatives and columns represent criteria. Each cell contains the performance value of an alternative for a specific criterion.\n",
    "\n",
    "\\begin{array}{c|cccc}\n",
    " & C_1 & C_2 & \\dots & C_n \\\\\n",
    "\\hline\n",
    "A_1 & x_{11} & x_{12} & \\dots & x_{1n} \\\\\n",
    "A_2 & x_{21} & x_{22} & \\dots & x_{2n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "A_m & x_{m1} & x_{m2} & \\dots & x_{mn} \\\\\n",
    "\\end{array}\n",
    "\n",
    "Where:\n",
    "- \\($A_i$\\) represents the \\($i$\\)-th alternative (e.g., Laptop 1, Laptop 2, etc.)\n",
    "- \\($C_j$\\) represents the \\($j$\\)-th criterion (e.g., Price, Performance, etc.)\n",
    "- \\($x_{ij}$\\) is the value of alternative \\($i$\\) for criterion \\($j$\\)\n",
    "- \\($m$\\) is the number of alternatives\n",
    "- \\($n$\\) is the number of criteria\n",
    "\n",
    "2. **Normalize the Decision Matrix**: For each criterion, normalize the values (e.g., for benefit criteria: $x_{ij}' = x_{ij} / \\max(x_j)$; for cost criteria: $x_{ij}' = \\min(x_j) / x_{ij}$).\n",
    "\n",
    "3. **Assign Weights to Criteria**: Determine the relative importance of each criterion and assign a weight (sum of all weights = 1).\n",
    "\n",
    "4. **Calculate Weighted Scores**: Multiply each normalized value by its corresponding criterion weight.\n",
    "\n",
    "\n",
    "The SAW method calculates the final score for each alternative using:\n",
    "\n",
    "$$S_i = \\sum_{j=1}^{n} w_j \\times r_{ij}$$\n",
    "\n",
    "Where:\n",
    "- $S_i$ = Total score for alternative $i$\n",
    "- $w_j$ = Weight of criterion $j$\n",
    "- $r_{ij}$ = Normalized value of alternative $i$ for criterion $j$\n",
    "- $n$ = Number of criteria\n",
    "\n",
    "The alternative with the **highest score** is the best choice.\n",
    "\n",
    "5. **Aggregate Scores**: Sum the weighted scores for each alternative to get the final SAW score.\n",
    "6. **Rank the Alternatives**: Rank alternatives based on their SAW scores; the highest score is the best choice.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ec7dc",
   "metadata": {},
   "source": [
    "## Problem Statement: Selecting the Best Laptop\n",
    "\n",
    "Imagine you're shopping for a laptop and need to choose between 5 different models. You want to evaluate them based on multiple criteria:\n",
    "\n",
    "- **Price** (lower is better) - Cost consideration\n",
    "- **Performance Score** (higher is better) - Processing power\n",
    "- **Battery Life** (higher is better) - Hours of usage\n",
    "- **Weight** (lower is better) - Portability\n",
    "- **Screen Quality** (higher is better) - Display rating (1-10)\n",
    "\n",
    "Each criterion has different importance to you, and we'll use SAW to find the best overall choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfb4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.width', None)\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf3de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "file_path = input(\"Enter the path to the dataset XLSX file: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9665da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the XLSX file into Pandas DataFrame\n",
    "df = pd.read_excel(file_path, sheet_name='Ex1')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data types and basic info\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Alternatives: {len(df)} laptops\")\n",
    "print(f\"Criteria: {len(df.columns)-1} criteria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad83779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criteria weights (importance of each criterion)\n",
    "# Weights should sum to 1.0\n",
    "criteria_weights = {\n",
    "    'Price ($)': 0.25,            # 25% importance\n",
    "    'Performance Score': 0.30,    # 30% importance  \n",
    "    'Battery Life (hrs)': 0.20,   # 20% importance\n",
    "    'Weight (kg)': 0.15,          # 15% importance\n",
    "    'Screen Quality (1-10)': 0.10 # 10% importance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0233b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array for calculations\n",
    "weights = np.array(list(criteria_weights.values()))\n",
    "\n",
    "print(\"Criteria Weights:\")\n",
    "print(\"=\"*30)\n",
    "for criterion, weight in criteria_weights.items():\n",
    "    print(f\"{criterion:<20}: {weight:.2f} ({weight*100:.0f}%)\")\n",
    "\n",
    "print(f\"\\nTotal weight sum: {weights.sum():.2f}\")\n",
    "\n",
    "# Verify weights sum to 1\n",
    "if abs(weights.sum() - 1.0) < 0.001:\n",
    "    print(\"Weights sum to 1.0\")\n",
    "else:\n",
    "    print(\"Warning: Weights do not sum to 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14356e6",
   "metadata": {},
   "source": [
    "## Step 1: Normalization\n",
    "\n",
    "Before applying weights, we need to normalize the criteria values to a common scale (0-1). There are different normalization methods:\n",
    "\n",
    "### 1. **Min-Max Normalization**\n",
    "- **For Benefit criteria** (higher is better): $r_{ij} = \\frac{x_{ij} - \\min_j(x_{ij})}{\\max_j(x_{ij}) - \\min_j(x_{ij})}$\n",
    "- **For Cost criteria** (lower is better): $r_{ij} = \\frac{\\max_j(x_{ij}) - x_{ij}}{\\max_j(x_{ij}) - \\min_j(x_{ij})}$\n",
    "\n",
    "### 2. **Linear Scale Transformation**\n",
    "- **For Benefit criteria**: $r_{ij} = \\frac{x_{ij}}{\\max_j(x_{ij})}$\n",
    "- **For Cost criteria**: $r_{ij} = \\frac{\\min_j(x_{ij})}{x_{ij}}$\n",
    "\n",
    "We'll use **Min-Max normalization** as it's the most intuitive and commonly used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adcb34c",
   "metadata": {},
   "source": [
    "Both Min-Max Normalization and Linear Scale Transformation are used to bring different criteria onto a common scale, but they do so differently and are suitable for different situations.\n",
    "\n",
    "### Min-Max Normalization\n",
    "\n",
    "This is the most common and generally recommended method for SAW. It scales every value to a fixed range of [0, 1], where the best-performing alternative for a criterion gets a score of 1 and the worst gets a score of 0.\n",
    "\n",
    "*   **When to use:**\n",
    "    *   When you want a true relative comparison where the full range of performance (from worst to best) is captured.\n",
    "    *   When you want all normalized criteria to be on the exact same [0, 1] scale.\n",
    "    *   It is the standard and most intuitive method for SAW.\n",
    "\n",
    "### Linear Scale Transformation\n",
    "\n",
    "This method scales values relative to a single pointâ€”either the maximum value (for benefit criteria) or the minimum value (for cost criteria). The range is not strictly [0, 1].\n",
    "\n",
    "*   **When to use:**\n",
    "    *   When you want to evaluate performance as a proportion of the \"best\" available option. For example, for a benefit criterion, a value is judged as a percentage of the maximum observed value.\n",
    "    *   When the absolute minimum is not a meaningful baseline.\n",
    "\n",
    "### What to Be Careful About\n",
    "\n",
    "1.  **Outliers (Critical for Min-Max):** Min-Max normalization is very sensitive to outliers. A single extreme value (either very high or very low) will become the `max` or `min` in the formula, which can squash all the other \"normal\" data points into a very small range, reducing their differentiation.\n",
    "\n",
    "2.  **Division by Zero (Critical for Linear Scale):** The cost formula for Linear Scale Transformation is `min(x) / x`. If any alternative has a value of `0` for a cost criterion, this will result in a division-by-zero error.\n",
    "\n",
    "3.  **Interpretation:** The two methods produce different normalized values, which can lead to different final rankings. Min-Max measures where a value falls within the full observed range, while Linear Scale measures it relative to the best value. Be consistent and understand which interpretation fits your problem better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define normalization functions\n",
    "def normalize_benefit_criterion(values):\n",
    "    \"\"\"\n",
    "    Normalize benefit criterion (higher is better)\n",
    "    Formula: (value - min) / (max - min)\n",
    "    \"\"\"\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    if max_val == min_val:\n",
    "        return np.ones_like(values)  # All values are the same\n",
    "    return (values - min_val) / (max_val - min_val)\n",
    "\n",
    "def normalize_cost_criterion(values):\n",
    "    \"\"\"\n",
    "    Normalize cost criterion (lower is better)\n",
    "    Formula: (max - value) / (max - min)\n",
    "    \"\"\"\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    if max_val == min_val:\n",
    "        return np.ones_like(values)  # All values are the same\n",
    "    return (max_val - values) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criterion types (benefit or cost)\n",
    "criterion_types = {\n",
    "    'Price ($)': 'cost',                # Lower price is better\n",
    "    'Performance Score': 'benefit',     # Higher performance is better\n",
    "    'Battery Life (hrs)': 'benefit',    # Longer battery life is better\n",
    "    'Weight (kg)': 'cost',              # Lower weight is better\n",
    "    'Screen Quality (1-10)': 'benefit'  # Higher quality is better\n",
    "}\n",
    "\n",
    "print(\"Criterion Types:\")\n",
    "print(\"=\"*25)\n",
    "for criterion, type_ in criterion_types.items():\n",
    "    print(f\"{criterion:<20}: {type_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f452ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to each criterion\n",
    "normalized_data = df.copy()\n",
    "\n",
    "print(\"Normalization Process:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for criterion in criterion_types.keys():\n",
    "    values = df[criterion].values\n",
    "    \n",
    "    print(f\"\\n{criterion}:\")\n",
    "    print(f\"  Original values: {values}\")\n",
    "    print(f\"  Type: {criterion_types[criterion]}\")\n",
    "    \n",
    "    if criterion_types[criterion] == 'benefit':\n",
    "        normalized_values = normalize_benefit_criterion(values)\n",
    "    else:\n",
    "        normalized_values = normalize_cost_criterion(values)\n",
    "    \n",
    "    normalized_data[criterion] = normalized_values\n",
    "    print(f\"  Normalized: {normalized_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c93e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NORMALIZED DECISION MATRIX:\")\n",
    "print(\"=\"*50)\n",
    "print(normalized_data.to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8944b38",
   "metadata": {},
   "source": [
    "## Step 2: Apply SAW Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SAW scores\n",
    "def calculate_saw_scores(normalized_matrix, weights):\n",
    "    \"\"\"\n",
    "    Calculate SAW scores for each alternative\n",
    "    \"\"\"\n",
    "    # Extract only the criteria columns (exclude 'Laptop' column)\n",
    "    criteria_columns = [col for col in normalized_matrix.columns if col != 'Laptop']\n",
    "    criteria_data = normalized_matrix[criteria_columns].values\n",
    "    \n",
    "    # Calculate weighted sum for each alternative\n",
    "    scores = np.dot(criteria_data, weights)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb15a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get normalized criteria data\n",
    "criteria_columns = [col for col in normalized_data.columns if col != 'Laptop']\n",
    "normalized_matrix = normalized_data[criteria_columns].values\n",
    "\n",
    "print(\"Calculation Details:\")\n",
    "print(\"=\"*50)\n",
    "print(\"Normalized Matrix (criteria only):\")\n",
    "print(normalized_matrix)\n",
    "print(f\"\\nWeights: {weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01bf4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SAW scores\n",
    "saw_scores = calculate_saw_scores(normalized_data, weights)\n",
    "\n",
    "# Create results dataframe\n",
    "results = pd.DataFrame({\n",
    "    'Laptop': df['Laptop'],\n",
    "    'SAW Score': saw_scores\n",
    "})\n",
    "\n",
    "# Add detailed breakdown\n",
    "print(f\"\\nSAW Score Calculation:\")\n",
    "print(\"=\"*30)\n",
    "for i, laptop in enumerate(df['Laptop']):\n",
    "    print(f\"\\n{laptop}:\")\n",
    "    total = 0\n",
    "    for j, criterion in enumerate(criteria_columns):\n",
    "        contribution = normalized_matrix[i, j] * weights[j]\n",
    "        total += contribution\n",
    "        print(f\"  {criterion:<20}: {normalized_matrix[i, j]:.4f} Ã— {weights[j]:.3f} = {contribution:.4f}\")\n",
    "    print(f\"  {'Total SAW Score':<20}: {total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e663879",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*50}\")\n",
    "print(\"FINAL SAW SCORES:\")\n",
    "print(\"=\"*50)\n",
    "results_sorted = results.sort_values('SAW Score', ascending=False)\n",
    "print(results_sorted.to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c33dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ranking to results\n",
    "results_sorted['Rank'] = range(1, len(results_sorted) + 1)\n",
    "\n",
    "print(\"FINAL RANKING:\")\n",
    "print(\"=\"*40)\n",
    "for idx, row in results_sorted.iterrows():\n",
    "    print(f\"{row['Rank']}. {row['Laptop']:<10} - Score: {row['SAW Score']:.4f}\")\n",
    "\n",
    "# Best choice\n",
    "best_laptop = results_sorted.iloc[0]\n",
    "print(f\"\\nBEST CHOICE: {best_laptop['Laptop']}\")\n",
    "print(f\"SAW Score: {best_laptop['SAW Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b3400",
   "metadata": {},
   "source": [
    "## Step 3: Sensitivity Analysis\n",
    "\n",
    "Let's perform a sensitivity analysis to see how changes in weights affect the ranking. This helps us understand the robustness of our decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f18960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis(base_weights, criterion_index, weight_range):\n",
    "    \"\"\"\n",
    "    Perform sensitivity analysis by varying a single criterion's weight.\n",
    "\n",
    "    For each candidate weight in weight_range this function:\n",
    "      - creates a test weight vector by setting the selected criterion to the candidate weight,\n",
    "      - proportionally redistributes the remaining weight (1 - candidate) across the other criteria,\n",
    "      - computes SAW scores using the global `normalized_data` and the existing `calculate_saw_scores` function,\n",
    "      - records the winner (alternative with highest SAW score) and the full score vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_weights : array-like of float\n",
    "        Original weights for all criteria (expected to sum approximately to 1.0).\n",
    "    criterion_index : int\n",
    "        Zero-based index of the criterion whose weight will be varied.\n",
    "    weight_range : iterable of float\n",
    "        Sequence of candidate weights to try for the selected criterion (each value must be in [0, 1]).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dictionaries\n",
    "        Each dictionary corresponds to one tested weight and contains:\n",
    "          - 'Performance Weight' : float  (the tested weight value)\n",
    "          - 'Winner'             : str    (name of the winning alternative)\n",
    "          - 'Winning Score'      : float  (SAW score of the winner)\n",
    "          - 'All Scores'         : numpy.ndarray (SAW scores for all alternatives, same order as df['Laptop'])\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Redistribution of remaining weight is proportional to the current weights of the other criteria.\n",
    "      If the sum of other weights is zero, other weights remain zero and the selected weight is used as-is.\n",
    "    - The function does not modify `base_weights`; it works on copies.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    sensitivity_results = sensitivity_analysis(weights, performance_index, np.arange(0.1, 0.6, 0.05))\n",
    "    \"\"\"\n",
    "    results_list = []\n",
    "\n",
    "    # Basic validation\n",
    "    n = len(base_weights)\n",
    "    if not (0 <= criterion_index < n):\n",
    "        raise IndexError(f\"criterion_index {criterion_index} out of range for weights length {n}\")\n",
    "\n",
    "    for new_weight in weight_range:\n",
    "        if not (0.0 <= new_weight <= 1.0):\n",
    "            raise ValueError(f\"Test weight must be in [0, 1], got {new_weight}\")\n",
    "\n",
    "        # Create new weight vector\n",
    "        test_weights = base_weights.copy()\n",
    "        test_weights[criterion_index] = new_weight\n",
    "\n",
    "        # Redistribute remaining weight proportionally\n",
    "        remaining_weight = 1.0 - new_weight\n",
    "        other_indices = [i for i in range(len(test_weights)) if i != criterion_index]\n",
    "        current_other_sum = sum(test_weights[i] for i in other_indices)\n",
    "\n",
    "        if current_other_sum > 0:\n",
    "            for i in other_indices:\n",
    "                test_weights[i] = test_weights[i] * (remaining_weight / current_other_sum)\n",
    "\n",
    "        # Calculate SAW scores with new weights\n",
    "        test_scores = calculate_saw_scores(normalized_data, test_weights)\n",
    "\n",
    "        # Get ranking\n",
    "        test_results = pd.DataFrame({\n",
    "            'Laptop': df['Laptop'],\n",
    "            'SAW Score': test_scores\n",
    "        }).sort_values('SAW Score', ascending=False)\n",
    "\n",
    "        results_list.append({\n",
    "            'Performance Weight': float(new_weight),\n",
    "            'Winner': test_results.iloc[0]['Laptop'],\n",
    "            'Winning Score': float(test_results.iloc[0]['SAW Score']),\n",
    "            'All Scores': test_scores\n",
    "        })\n",
    "\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38936db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sensitivity analysis on Performance Score weight\n",
    "performance_index = 1  # Performance Score is at index 1\n",
    "weight_range = np.arange(0.1, 0.6, 0.05)  # From 10% to 55% in 5% steps\n",
    "\n",
    "sensitivity_results = sensitivity_analysis(weights, performance_index, weight_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64182ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SENSITIVITY ANALYSIS: Performance Score Weight\")\n",
    "print(\"=\"*50)\n",
    "print(\"Testing how changes in Performance weight affect the winner.\")\n",
    "\n",
    "# Display results\n",
    "winners = {}\n",
    "for result in sensitivity_results:\n",
    "    perf_weight = result['Performance Weight']\n",
    "    winner = result['Winner']\n",
    "    winning_score = result['Winning Score']\n",
    "    \n",
    "    if winner not in winners:\n",
    "        winners[winner] = []\n",
    "    winners[winner].append(perf_weight)\n",
    "    \n",
    "    print(f\"Performance Weight: {perf_weight:.2f} ({perf_weight*100:.0f}%) -> Winner: {winner} (Score: {winning_score:.4f})\")\n",
    "\n",
    "print(f\"\\nWINNER SUMMARY:\")\n",
    "print(\"=\"*30)\n",
    "for laptop, weight_ranges in winners.items():\n",
    "    print(f\"{laptop}: Wins when Performance weight is {min(weight_ranges):.2f}-{max(weight_ranges):.2f}\")\n",
    "\n",
    "# Visualize sensitivity analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot scores vs performance weight for each laptop\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "for i, laptop in enumerate(df['Laptop']):\n",
    "    scores = [result['All Scores'][i] for result in sensitivity_results]\n",
    "    plt.plot(weight_range, scores, marker='o', label=laptop, color=colors[i], linewidth=2)\n",
    "\n",
    "plt.axvline(x=weights[performance_index], color='black', linestyle='--', \n",
    "           label=f'Current Weight ({weights[performance_index]:.2f})', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Performance Score Weight')\n",
    "plt.ylabel('SAW Score')\n",
    "plt.title('Sensitivity Analysis: SAW Scores vs Performance Weight')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check stability around current weight\n",
    "current_weight = weights[performance_index]\n",
    "tolerance = 0.05\n",
    "stable_range = [w for w in weight_range if abs(w - current_weight) <= tolerance]\n",
    "stable_winners = [result['Winner'] for result in sensitivity_results \n",
    "                 if result['Performance Weight'] in stable_range]\n",
    "\n",
    "print(f\"\\nSTABILITY ANALYSIS:\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Current Performance weight: {current_weight:.2f}\")\n",
    "print(f\"Within Â±{tolerance:.2f} range:\")\n",
    "if len(set(stable_winners)) == 1:\n",
    "    print(f\"Stable winner: {stable_winners[0]}\")\n",
    "else:\n",
    "    print(f\"Winner changes: {set(stable_winners)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83428e9",
   "metadata": {},
   "source": [
    "## SAW Method: Advantages and Disadvantages\n",
    "\n",
    "### Advantages\n",
    "\n",
    "1. **Simplicity**: Easy to understand and implement\n",
    "2. **Intuitive**: Linear aggregation is natural for decision makers\n",
    "3. **Transparency**: Clear how each criterion contributes to final score\n",
    "4. **Computational Efficiency**: Fast calculation even for large problems\n",
    "5. **Flexibility**: Works with both quantitative and qualitative criteria\n",
    "6. **Wide Applicability**: Suitable for various decision-making contexts\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "1. **Assumption of Additivity**: Assumes criteria are independent (no interactions)\n",
    "2. **Compensation**: Poor performance in one criterion can be completely offset by good performance in others\n",
    "3. **Weight Sensitivity**: Results can be sensitive to weight changes\n",
    "4. **Normalization Dependency**: Different normalization methods can yield different results\n",
    "5. **No Uncertainty Handling**: Doesn't account for uncertainty in data or preferences\n",
    "6. **Linear Relationships**: Assumes linear relationships between criteria and utility\n",
    "\n",
    "### When to Use SAW\n",
    "\n",
    "**Best for:**\n",
    "- Simple decision problems with independent criteria\n",
    "- When compensation between criteria is acceptable\n",
    "- Situations requiring transparent, explainable decisions\n",
    "- Problems with well-defined, measurable criteria\n",
    "\n",
    "**Avoid when:**\n",
    "- Criteria have complex interactions\n",
    "- Compensation is not acceptable (e.g., safety-critical decisions)\n",
    "- High uncertainty in data or preferences\n",
    "- Non-linear relationships between criteria and utility\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Normalization is Critical**: Choose appropriate normalization method for your data\n",
    "2. **Weight Carefully**: Ensure weights truly reflect importance and sum to 1.0\n",
    "3. **Check Sensitivity**: Test how weight changes affect results\n",
    "4. **Validate Results**: Compare with other MCDM methods when possible\n",
    "5. **Consider Context**: Ensure SAW assumptions fit your decision problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952246f0",
   "metadata": {},
   "source": [
    "## Practice Exercise\n",
    "\n",
    "Load the smartphone dataset and implement the SAW method to evaluate the smartphones.\n",
    "\n",
    "**Criteria:**\n",
    "- **Price** (cost criterion): Lower is better\n",
    "- **Camera Quality** (benefit criterion): Higher score is better (1-10)\n",
    "- **Battery Capacity** (benefit criterion): mAh, higher is better  \n",
    "- **Storage** (benefit criterion): GB, higher is better\n",
    "- **Brand Reputation** (benefit criterion): Rating 1-10, higher is better\n",
    "\n",
    "**Your Task:**\n",
    "1. Create the decision matrix\n",
    "2. Define your own weights based on your preferences\n",
    "3. Apply the SAW method\n",
    "4. Interpret the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdcm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
